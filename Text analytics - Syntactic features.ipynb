{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.tokenize import PunktSentenceTokenizer, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "**pos_list** is the list of tags used by the nltk pos tagger.\n",
    "\n",
    "\n",
    "**X_tags** are lists of the different tags used by the stanford parser. See https://gist.github.com/nlothian/9240750.\n",
    "\n",
    "\n",
    "**path** should point to the folder where the stanford-parser/model files were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_list = '$ \\'\\' ( ) , -- . : CC CD DT EX FW IN JJ JJR JJS MD NN NNP NNPS NNS PDT POS PRP PRP$ RB RBR RBS RP SYM TO UH VB VBD VBG VBN VBP VBZ WDT WP WP$ WRB `` LS'.split()\n",
    "\n",
    "word_tags = 'CC CD DT EX FW IN JJ JJR JJS LS MD NN NNS NNP NNPS PDT POS PRP PRP$ RB RBR RBS RP SYM TO UH VB VBD VBG VBN VBP VBZ WDT WP WP$ WRB # -LRB- -RRB- -None-'.split()\n",
    "phrase_tags = 'ADJP ADVP CONJP FRAG INTJ LST NAC NP NX PP PRN PRT QP RRC UCP VP WHADJP WHAVP WHNP WHPP X WHADVP'.split()\n",
    "clause_tags = 'S SBAR SBARQ SINV SQ'.split()\n",
    "punc_tags = '$ \\'\\' ( ) , -- . : ``'.split()\n",
    "\n",
    "all_tags = word_tags + phrase_tags + clause_tags + punc_tags\n",
    "list_of_tag_cats = [word_tags, phrase_tags, clause_tags, punc_tags]\n",
    "\n",
    "path = 'C:\\\\Users\\\\Eoin\\\\Documents\\\\5 MAI\\\\Text Analytics\\\\stanford-parser-full-2018-02-27'\n",
    "sp = StanfordParser(path_to_jar=path + '\\\\stanford-parser.jar',\n",
    "                    path_to_models_jar=path + '\\\\stanford-parser-3.9.1-models.jar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_common_word_list(text, size=100):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop.update(',', '\\'s', '(', ')', 'applause', '.', '--', ':', '[', ']')\n",
    "    word_dict = defaultdict(int)\n",
    "    for block, _ in text:\n",
    "        for sent in block:\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "                word_dict[word.lower()] += 1\n",
    "    s = [(k, word_dict[k]) for k in sorted(word_dict, key=word_dict.get, reverse=True) if k not in stop]\n",
    "    return [p for p, _ in s[:size]]\n",
    "\n",
    "def get_max_width(node):\n",
    "    stack = [node]\n",
    "    max_width = 0\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if isinstance(node, str):\n",
    "            continue\n",
    "        max_width = max(max_width, len(node))\n",
    "        for child in node:\n",
    "            stack.append(child)\n",
    "    return max_width\n",
    "\n",
    "def create_blocks(texts, chunk_size=10):\n",
    "    blocks = []\n",
    "    for text in texts:\n",
    "        sents = [sent for sent in sent_tokenize(state_union.raw(text))]\n",
    "        blocks += [(sents[i:i+chunk_size], text) for i in range(0, len(sents), chunk_size)]\n",
    "    return blocks\n",
    "\n",
    "def normalize_counts(array):\n",
    "    if array.sum():\n",
    "        array = array / array.sum()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis functions\n",
    "\n",
    "Functions for creating features sets for blocks of texts\n",
    "\n",
    "**full_analysis:** records all phrasal and word tags produced by Stanford parser as well as tree height and max width. Normalises each category of tag values and averages tree heights/widths for the given block of text. **slow**\n",
    "\n",
    "**simple analysis:** records pos for given block of text using nltk pos tagger. Normalises values.\n",
    "\n",
    "**word_analysis:** records how frequently popular words are used, also gets average word and sentence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_analysis(text):\n",
    "    heights = []\n",
    "    widths = []\n",
    "    words_dict = {pos: 0 for pos in all_tags}\n",
    "    for parses in sp.raw_parse_sents(text):\n",
    "        for parse in parses:\n",
    "            for prod in parse.productions()[1:]:\n",
    "                words_dict[prod.lhs().__str__()] += 1\n",
    "            widths.append(get_max_width(parse))\n",
    "            heights.append(parse.height())\n",
    "\n",
    "    features = np.array([sum(heights) / len(heights), sum(widths) / len(widths)], dtype='float64')\n",
    "    for tag_cat in list_of_tag_cats:\n",
    "        tag_counts = [words_dict[tag] for tag in tag_cat]\n",
    "        features = np.append(features, normalize_counts(np.array(tag_counts, dtype='float64')))\n",
    "    return features\n",
    "\n",
    "def simple_analysis(text):\n",
    "    pos_dict = {pos: 0 for pos in pos_list}\n",
    "    for sent in text:\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        for tag in tagged:\n",
    "            pos_dict[tag[1]] += 1\n",
    "    pos_count = list(pos_dict.values())\n",
    "    features = normalize_counts(np.array(pos_count, dtype='float64'))   \n",
    "    return features\n",
    "\n",
    "def word_analysis(text):\n",
    "    sent_lengths = []\n",
    "    word_lengths = []\n",
    "    word_dict = {word: 0 for word in word_list}\n",
    "    for sent in text:\n",
    "        sent_lengths.append(len(sent))\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            word_lengths.append(len(word))\n",
    "            if word in word_list:\n",
    "                word_dict[word.lower()] += 1\n",
    "    features = np.array([sum(sent_lengths) / len(sent_lengths), sum(word_lengths) / len(word_lengths)], dtype='float64')\n",
    "    word_counts = [word_dict[word] for word in word_list]\n",
    "    features = np.append(features, normalize_counts(np.array(word_counts, dtype='float64')))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def create_dataset(blocks, analysis_func):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for text, label in blocks:\n",
    "        features.append(analysis_func(text))\n",
    "        label = label[5:-4]\n",
    "        if label[-2] == '-':\n",
    "            label = label[:-2]\n",
    "        labels.append(label)\n",
    "\n",
    "    return features, labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build datasets\n",
    "\n",
    "I used state of the union addresses since they come built in with nltk and are a good proxy while we don't have our dataset yet. All files take the format year-president.txt as far back as 1945-Truman.txt. Sampling the blocks of texts sppeds up the process since the Stanford parser is pretty slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = ['2005-GWBush.txt', '2004-GWBush.txt', '2002-GWBush.txt', \n",
    "                     '1995-Clinton.txt', '1997-Clinton.txt','1993-Clinton.txt',\n",
    "                     '1996-Clinton.txt', '1998-Clinton.txt', '2003-GWBush.txt', '2004-GWBush.txt']\n",
    "test_examples = ['2006-GWBush.txt', '1994-Clinton.txt', '1999-Clinton.txt', '2001-GWBush-1.txt']\n",
    "\n",
    "training_set = create_blocks(training_examples)\n",
    "test_set = random.sample(create_blocks(test_examples), 50)\n",
    "\n",
    "word_list = create_common_word_list(training_set)\n",
    "\n",
    "train_data, train_labels = create_dataset(training_set, word_analysis)\n",
    "test_data, test_labels = create_dataset(test_set, word_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC \n",
      "training score: 0.47368421052631576 \n",
      "test     score: 0.52\n",
      "\n",
      "\n",
      "MultinomialNB \n",
      "training score: 0.7397660818713451 \n",
      "test     score: 0.74\n",
      "\n",
      "\n",
      "GaussianNB \n",
      "training score: 0.8947368421052632 \n",
      "test     score: 0.8\n",
      "\n",
      "\n",
      "LogisticRegression \n",
      "training score: 0.7485380116959064 \n",
      "test     score: 0.8\n",
      "\n",
      "\n",
      "SGDClassifier \n",
      "training score: 0.4619883040935672 \n",
      "test     score: 0.52\n",
      "\n",
      "\n",
      "RandomForestClassifier \n",
      "training score: 0.9970760233918129 \n",
      "test     score: 0.74\n",
      "\n",
      "\n",
      "AdaBoostClassifier \n",
      "training score: 0.9970760233918129 \n",
      "test     score: 0.94\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sgd = SGDClassifier()\n",
    "rfc = RandomForestClassifier() \n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "clfs = [svc, mnb, gnb, lr, sgd, rfc, abc]\n",
    "for clf in clfs:\n",
    "    clf.fit(train_data, train_labels)\n",
    "    print('{0} \\ntraining score: {1} \\ntest     score: {2}\\n\\n'.format(type(clf).__name__, \n",
    "                                                               clf.score(train_data, train_labels),\n",
    "                                                               clf.score(test_data, test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full parse tree features\n",
    "\n",
    "**LinearSVC**\n",
    "\n",
    "\n",
    "training score: 0.8450292397660819 \n",
    "\n",
    "\n",
    "test     score: 0.88\n",
    "\n",
    "\n",
    "**MultinomialNB** \n",
    "\n",
    "\n",
    "training score: 0.6783625730994152 \n",
    "\n",
    "\n",
    "test     score: 0.58\n",
    "\n",
    "\n",
    "**GaussianNB**\n",
    "\n",
    "\n",
    "training score: 0.827485380116959 \n",
    "\n",
    "\n",
    "test     score: 0.92\n",
    "\n",
    "\n",
    "**LogisticRegression**\n",
    "\n",
    "\n",
    "training score: 0.7894736842105263 \n",
    "\n",
    "\n",
    "test     score: 0.82\n",
    "\n",
    "\n",
    "**SGDClassifier** \n",
    "\n",
    "\n",
    "training score: 0.6403508771929824 \n",
    "\n",
    "\n",
    "test     score: 0.5\n",
    "\n",
    "\n",
    "**RandomForestClassifier**\n",
    "\n",
    "\n",
    "training score: 0.9912280701754386 \n",
    "\n",
    "\n",
    "test     score: 0.98\n",
    "\n",
    "\n",
    "**AdaBoostClassifier** \n",
    "\n",
    "\n",
    "training score: 1.0\n",
    "\n",
    "\n",
    "test     score: 0.92\n",
    "\n",
    "---\n",
    "\n",
    "# POS features\n",
    "\n",
    "**LinearSVC**\n",
    "\n",
    "training score: 0.8362573099415205 \n",
    "\n",
    "\n",
    "test     score: 0.78\n",
    "\n",
    "\n",
    "**MultinomialNB** \n",
    "\n",
    "\n",
    "training score: 0.5409356725146199 \n",
    "\n",
    "\n",
    "test     score: 0.56\n",
    "\n",
    "\n",
    "**GaussianNB**\n",
    "\n",
    "\n",
    "training score: 0.9093567251461988 \n",
    "\n",
    "\n",
    "test     score: 0.96\n",
    "\n",
    "\n",
    "**LogisticRegression** \n",
    "\n",
    "\n",
    "training score: 0.6345029239766082 \n",
    "\n",
    "\n",
    "test     score: 0.62\n",
    "\n",
    "\n",
    "**SGDClassifier**\n",
    "\n",
    "\n",
    "training score: 0.47076023391812866 \n",
    "\n",
    "\n",
    "test     score: 0.44\n",
    "\n",
    "\n",
    "**RandomForestClassifier** \n",
    "\n",
    "\n",
    "training score: 0.9883040935672515 \n",
    "\n",
    "\n",
    "test     score: 0.94\n",
    "\n",
    "\n",
    "**AdaBoostClassifier**\n",
    "\n",
    "\n",
    "training score: 1.0 \n",
    "\n",
    "\n",
    "test     score: 0.94\n",
    "\n",
    "---\n",
    "\n",
    "# Word features\n",
    "\n",
    "**LinearSVC**\n",
    "\n",
    "\n",
    "training score: 0.47368421052631576 \n",
    "\n",
    "\n",
    "test     score: 0.52\n",
    "\n",
    "\n",
    "**MultinomialNB** \n",
    "\n",
    "\n",
    "training score: 0.7397660818713451 \n",
    "\n",
    "\n",
    "test     score: 0.74\n",
    "\n",
    "\n",
    "**GaussianNB**\n",
    "\n",
    "\n",
    "training score: 0.8947368421052632 \n",
    "\n",
    "\n",
    "test     score: 0.8\n",
    "\n",
    "\n",
    "**LogisticRegression** \n",
    "\n",
    "\n",
    "training score: 0.7485380116959064 \n",
    "\n",
    "\n",
    "test     score: 0.8\n",
    "\n",
    "\n",
    "**SGDClassifier**\n",
    "\n",
    "\n",
    "training score: 0.4619883040935672 \n",
    "\n",
    "\n",
    "test     score: 0.52\n",
    "\n",
    "\n",
    "**RandomForestClassifier**\n",
    "\n",
    "\n",
    "training score: 0.9970760233918129 \n",
    "\n",
    "\n",
    "test     score: 0.74\n",
    "\n",
    "\n",
    "**AdaBoostClassifier**\n",
    "\n",
    "\n",
    "training score: 0.9970760233918129 \n",
    "\n",
    "\n",
    "test     score: 0.94"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
